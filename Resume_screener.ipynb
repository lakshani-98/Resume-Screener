{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSFJXR6AsiU5"
      },
      "outputs": [],
      "source": [
        "pip install langchain langgraph openai pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community"
      ],
      "metadata": {
        "id": "di6TGKkAuOWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import langgraph\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from langgraph.graph import StateGraph"
      ],
      "metadata": {
        "id": "yoSkjikps2iV"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('/content/config.env')\n",
        "\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key )"
      ],
      "metadata": {
        "id": "lM5kdkv18bIT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "KqLE4s3kvgR_",
        "outputId": "078e30d8-b65f-465b-e021-62cef174b8c7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4178c721-085e-4495-b85d-ed9f4dd06403\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4178c721-085e-4495-b85d-ed9f4dd06403\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Lakshani_Galwatta_CV.pdf to Lakshani_Galwatta_CV.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Job Requirement\n",
        "JOB_REQUIREMENTS = \"\"\"\n",
        "We are looking for a Software Engineer with:\n",
        "- Strong experience in Python and JavaScript.\n",
        "- Familiarity with Machine Learning and Data Science.\n",
        "- Knowledge of cloud services (AWS, Azure, or GCP).\n",
        "- At least 3 years of experience in software development.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pGWcpGLru4sl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "QkZhqKUevBxS"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to analyze resume's content and compares it against job requirements\n",
        "def analyze_resume_with_openai(resume_text, job_requirements):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI assistant trained to evaluate resumes for job suitability.\"},\n",
        "        {\"role\": \"system\", \"content\": f\"Job Requirements: {job_requirements}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Resume Content: {resume_text}\"},\n",
        "        {\"role\": \"system\", \"content\": \"Please evaluate how well the resume matches the job requirements.\"}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=1,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "rrrNm1oOA2-J"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify resume based on analysis\n",
        "def classify_resume_with_openai(analysis):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI assistant trained to classify resumes based on suitability for a job.\"},\n",
        "        {\"role\": \"system\", \"content\": f\"Analysis of Resume: {analysis}\"},\n",
        "        {\"role\": \"system\", \"content\": \"Classify the candidate into one of the following categories: STRONG MATCH: If they meet all key requirements., NEEDS IMPROVEMENT: If they partially meet the requirements., or NOT SUITABLE: If they lack most skills.\"},\n",
        "        {\"role\": \"system\", \"content\": \" Do not include any explanations or additional details; respond with only one of these categories.\"}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=1,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "lfmjqluGEitN"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, TypedDict, Optional\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage\n",
        "\n",
        "# Define the state structure using TypedDict\n",
        "class ResumeState(TypedDict):\n",
        "    resume_text: Optional[str] = None\n",
        "    analysis: Optional[str] = None\n",
        "    classification: Optional[str] = None\n",
        "    job_requirements: Optional[str] = None\n",
        "\n",
        "\n",
        "# Define the Resume Screening Graph\n",
        "graph = StateGraph(ResumeState)\n",
        "\n",
        "# Step 1: Analyze Resume\n",
        "def analyze_resume(state: ResumeState):\n",
        "    print(\"ðŸ”¹ Analyzing Resume...\")\n",
        "    analysis = analyze_resume_with_openai(state[\"resume_text\"], state[\"job_requirements\"])\n",
        "    return {\"analysis\": analysis}\n",
        "\n",
        "# Step 2: Classify Candidate\n",
        "def classify_resume(state: ResumeState):\n",
        "    print(\"ðŸ”¹ Classifying Candidate...\")\n",
        "    classification = classify_resume_with_openai(state[\"analysis\"])\n",
        "    return {\"classification\": classification}\n",
        "\n",
        "# Add nodes to the graph\n",
        "graph.add_node(\"analyze_resume\", analyze_resume)\n",
        "graph.add_node(\"classify_resume\", classify_resume)\n",
        "\n",
        "# Define workflow connections (set sequence of operations)\n",
        "graph.add_edge(\"analyze_resume\", \"classify_resume\")\n",
        "\n",
        "# Set the entry point (starting node)\n",
        "graph.set_entry_point(\"analyze_resume\")\n",
        "\n",
        "# Compile the graph to create the application\n",
        "app = graph.compile()\n"
      ],
      "metadata": {
        "id": "13sqdlNY3vNM"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the resume screening process\n",
        "def screen_resume(pdf_path: str, job_requirements: str)  -> Dict[str, str]:\n",
        "    print(\"ðŸ”¹ Extracting text from resume PDF...\")\n",
        "    resume_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    initial_state = ResumeState(resume_text=resume_text, job_requirements=job_requirements)\n",
        "    print(f\"ðŸ”¹ Initial State Created:{initial_state}\")\n",
        "\n",
        "    # Run the graph (invoke the workflow)\n",
        "    final_state = app.invoke(initial_state)\n",
        "\n",
        "    return {\n",
        "        \"Analysis\": final_state[\"analysis\"],\n",
        "        \"Classification\": final_state[\"classification\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "fxazWAUECCmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Run the resume screening process\n",
        "if __name__ == \"__main__\":\n",
        "    resume_file = \"/content/Lakshani_Galwatta_CV.pdf\"\n",
        "    print(\"ðŸ”¹ Running Resume Screening on:\")\n",
        "    result = screen_resume(resume_file, JOB_REQUIREMENTS)\n",
        "    print(\"ðŸ”¹ Resume Analysis:\\n\", result[\"Analysis\"])\n",
        "    print(\"\\nðŸ”¹ Candidate Classification:\", result[\"Classification\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtIx1joNH4Lf",
        "outputId": "edcc8108-6ccc-48ac-a534-1f75a3e38e72"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Running Resume Screening on:\n",
            "ðŸ”¹ Extracting text from resume PDF...\n",
            "ðŸ”¹ Initial State Created:{'resume_text': 'Lakshani Galwatta\\nSoftware Engineer\\nI am an enthusiastic, self motivated and hard working individual and I am keen to work for your reputable organization where\\nI can demonstrate my abilities while enhancing my skills, to achieve the company\\'s goals on time and with excellence.\\n+94 77 574 07 57\\nlakshani.galwatta@gmail.com\\nlakshani-galwatta\\nPython Engineer at Cove Island Industries Pvt Ltd\\nContributed to the UrsaLeo cloud base digital twin solution system.\\nConducted POC to integrate Things Board for real-time sensor data visualization.\\nImproved the RAG chatbot backend to answer user queries enhancing response relevance and optimizing response\\ntime.\\nConducted R&D to implement a RAG chatbot using ColPali and  GPT-4o models.\\nConducted R&D to identify optimal in-house multimodal model for chatbot development.\\nDesigned and implemented web based user interface for chatbot.\\nImplemented document upload system to Vector database using Apache NiFi.\\nDesigned and implemented web based user interfaces to upload documents to the Vector database, display a list of\\nuploaded documents to each twin and remove them.\\nImplemented functionality to extract the tower creation and antenna placing data from documents.\\nImplemented a web-based user interface to upload documents for tower data extraction and display the extracted\\ntower data and associated images.\\nDesigned and implemented Admin Dashboard for the client, digital twin and user management.\\nCreated Figma designs for the Admin Dashboard.\\nImplemented functionality to download documents from the Procore Construction Management Software and send  \\ndocuments to Vector Database, when a document is attached to a component in digital twin.\\nPrepared documentations and videos for knowledge sharing.\\nTechnologies: Python, TypeScript, Django, React, Spring Boot, GraphQL, PostgreSQL, AWS, Apache NiFi\\nSEP 2024 -  PRESENT\\nExperience\\nJAN 2023 - JUNE 2023 \\nTrainee Software Engineer at Etronic Solutions\\nSoftware Engineer Intern at DirectFN Sri Lanka\\nContributed to the DirectFN Admin Terminal of DFN Order Management System which is a client-side terminal designed\\nto streamline, automate and enhance the back-office workflows.\\nEngaged in Change Request tasks and Bug Fixes.\\nResolved issues in the frontend codebase identified by SonarQube.\\nConducted associated Unit Testing. \\nTechnologies : Angular, Java , Spring , Oracle , Karma, Jasmine, JUnit, Mockito\\nConducted Bug fixes.\\nTechnologies :  PHP, MySQL\\nSEP 2021 - NOV 2021\\nEducation\\nMSc in Data Science and Artificial Intelligence \\nUniversity of Moratuwa (Reading)\\nBSc (Hons) in Information Technology \\nUniversity of Moratuwa (2020-2024)\\nGPA : 3.83\\nSirimavo Bandaranaike Vidyalaya, Colombo 07 \\nA/L- Biological Science - AAB | Z-score 1.8106\\nO/L - 9A\\'s\\nDiploma in ICT & Computing \\nIDM Achievers International Campus (2019-2020)\\nLinkedIn\\nGitHub\\nReferees\\nDr Lochandaka Ranathunga\\nSenior Lecturer, Department of Information Technology, \\nFaculty of Information Technology, \\nUniversity of Moratuwa, \\nSri Lanka. Tel: +94 11 2650301 -Ext 8102 \\nMobile : +94 71 2207030 \\nEmail: lochandaka@uom.lk\\nMr. Kasun Wanniarachchi\\nSenior Tech Lead, \\nD F N Technology ( Pvt ) Ltd, \\nMalabe, Sri Lanka. \\nMobile: +94 77 1322505 \\nEmail: w.kasun@directfn.com\\nRoad to codeManiaâ€™21: Python Programmer by IEEE SLTC : Participant\\nJava Programming by Udemy\\nJava Using Alice by Oracle Academy Member Hub \\nCloud Data Pipeline Builder by AWS Academy\\nAWS Academy Data Engineering - AWS Academy\\nHacktitude by 99x : Participant \\nMicroservices and CI/CD Pipeline Builder - AWS Academy\\nNodeJS REST APIs Projects by Udemy\\nAdaGradâ€™ 21, Introduction to ML by IEEE SLTC : Participant\\nCertificates & Extracurricular Activities\\nFIT Future Careers 2024\\nCommittee Member - Company Calling and\\nCoordination\\nCode Rush 2022\\nCommittee Member - Registration Handling\\nRotaract Club - University of Moratuwa\\nVolunteer - \"Manusath Handa\" programme\\nSchool\\nHockey player\\nQualified in Prathma (Instrumental -\\nViolin) in Bhatkhande Sangit Vidyapith\\nHack Moral 4.0 - Mini Hackathon  by FIT: Participant\\nJava\\nPython\\nC\\nSQL: MySQL, MSSQL, PostgreSQL, Oracle\\nWeb: HTML, CSS, JS, TS, React, Angular, Django, Spring Boot\\nAWS\\nTesting Tools: Jasmine, Karma, JUnit, Mockito, Apache JMeter\\nSkills\\nVersion Control: Git, GitHub, Bitbucket\\nFigma\\nSonarQube\\nApache NiFi\\nTeamwork\\nQuick Learning\\nAdaptability\\nUniversity Projects\\nStorytelling Application for the Deaf Children Using Sri Lankan Sign Language\\nAn innovative application tailored for deaf children, which converts a sequence of images into a narrated story. The\\nnarration is delivered through Sri Lankan Sign Language using a 3D Animator, ensuring an inclusive and engaging\\nstorytelling experience. \\nTechnologies : Python, Flask, Random Forest Classifier, NLP\\nProject Management System\\n A web application designed to facilitate project tracking, issue management, and team collaboration.\\nTechnologies: React, JavaScript, Java, Spring Boot, MySQL, Shadcn UI, Tailwind CSS\\nWeb portal for Career Guidance Unit, University of Moratuwa\\nA web application with an admin dashboard with features to manage events, job vacancies and consultation sessions\\nand automatic email sending.\\nTechnologies: Angular, TypeScript, NodeJS, Express, JWT, MySQL, AWS, Bootstrap\\n PizzaMart\\nAn innovative application tailored for deaf children, which converts a sequence of images into a narrated story. The\\nnarration is delivered through Sri Lankan Sign Language using a 3D Animator, ensuring an inclusive and engaging\\nstorytelling experience. \\nTechnologies : JavaScript, Java, Spring Boot, MySQL \\n', 'job_requirements': '\\nWe are looking for a Software Engineer with:\\n- Strong experience in Python and JavaScript.\\n- Familiarity with Machine Learning and Data Science.\\n- Knowledge of cloud services (AWS, Azure, or GCP).\\n- At least 3 years of experience in software development.\\n'}\n",
            "ðŸ”¹ Analyzing Resume...\n",
            "ðŸ”¹ Classifying Candidate...\n",
            "ðŸ”¹ Resume Analysis:\n",
            " The resume of Lakshani Galwatta shows a promising profile, and here's how it aligns with the job requirements for the Software Engineer position:\n",
            "\n",
            "1. **Experience in Python and JavaScript:**\n",
            "   - The candidate has strong experience in Python through their current position and various projects, including using Flask and Django. \n",
            "   - They have used JavaScript in several projects and technologies like React and Angular, indicating proficiency in the language.\n",
            "\n",
            "2. **Familiarity with Machine Learning and Data Science:**\n",
            "   - The candidate is currently pursuing an MSc in Data Science and Artificial Intelligence, which illustrates a solid background in these fields. \n",
            "   - They have worked on a project involving a Random Forest Classifier and NLP, showcasing familiarity with machine learning concepts.\n",
            "\n",
            "3. **Knowledge of Cloud Services (AWS, Azure, or GCP):**\n",
            "   - They have experience with AWS, as mentioned in various roles and courses completed, indicating some level of proficiency with cloud services.\n",
            "\n",
            "4. **At least 3 Years of Experience in Software Development:**\n",
            "   - The candidate appears to have approximately 1 year of software engineering experience (Trainee and Intern roles) along with significant project experience during their studies. However, they may fall short of the 3-year mark of professional experience as specified.\n",
            "\n",
            "**Overall Assessment:**\n",
            "- Lakshani Galwatta possesses strong skills in Python and JavaScript, relevant experience with machine learning, and cloud services expertise, making them a suitable candidate for the position in terms of technical skills.\n",
            "- The main gap is in the required amount of professional work experience (3 years). The candidate has 1 year of documented experience, which may be considered insufficient for this role unless the employer is open to candidates with slightly less formal experience given their strong educational background and projects.\n",
            "\n",
            "In conclusion, while the resume displays a strong match in skills and knowledge areas, the limited work experience could be a barrier for this specific position, depending on the employer's flexibility regarding experience requirements.\n",
            "\n",
            "ðŸ”¹ Candidate Classification: NEEDS IMPROVEMENT\n"
          ]
        }
      ]
    }
  ]
}